# 1. Efficient BackProp: Classic Tricks and Modern Insights

## 1.1. Overview 
This repository contains a poster project summarizing the classic paper *Efficient BackProp* (LeCun et al., 1998), with added insights from modern deep learning practices.

本仓库展示的是对经典论文 *Efficient BackProp* 的总结型海报项目，同时对比现代深度学习中的相关训练技巧。

## 1.2. Objectives 
- Summarize training challenges in backpropagation  
  总结反向传播中的训练难点  
- Visualize classic training tricks proposed in the original paper  
  图示论文中的经典训练技巧  
- Highlight modern improvements like BatchNorm, ReLU, Adam  
  补充并对比现代主流优化技术（如 BatchNorm、ReLU、Adam）  

## 1.3. Files 
- `efficient-backprop-poster.pdf` – Final poster, visual summary and analysis  
- `backpropagation_flowchart.pdf` – Custom-drawn forward & backward propagation flowchart  

## 1.4. Key Concepts 
- Weight Initialization (Xavier Init vs. He Init)  
- Learning Rate Scheduling and Momentum  
- Activation Functions (tanh, sigmoid vs. ReLU family)  
- Normalization: from global preprocessing to BatchNorm/LayerNorm  
- Shuffling, adaptive learning, and training strategies  

## 1.5. My Contribution 
I was responsible for:
- Designing and laying out the poster  
- Creating all visual elements and flow diagrams  
- Writing and summarizing all content prior to the modern section  

## 1.6. Disclaimer 
- This project was created for educational purposes. No school names, assignment text, or copyrighted material are included.
- Note: One of the poster images—a meme-style graphic—was generated using an AI tool just for fun and visual effect.



